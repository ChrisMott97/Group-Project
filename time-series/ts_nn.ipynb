{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "import pymysql\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the data from the external database\n",
    "dbcon = pymysql.connect(user=\"root\", password=\"example\", database=\"humber_bridge\", host=\"localhost\", port=33061)\n",
    "data = pd.read_sql(\"select * from summary order by timestamp desc limit 1000\", dbcon)\n",
    "data.fillna(value = 0, inplace = True) # Replaces NoneType values with 0\n",
    "data.replace(1.1e308, 0, inplace = True) # Replaces infinite values with 0\n",
    "data = data[::-1]\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizes the data for use in the encoder\n",
    "ts_data = pd.DataFrame()\n",
    "cols = data.columns[1:]\n",
    "sensor = []\n",
    "timestamp = []\n",
    "value = []\n",
    "time_idx = []\n",
    "ti = 0\n",
    "for i in range(len(data[\"timestamp\"])):\n",
    "    for j in cols:\n",
    "        timestamp.append(data[\"timestamp\"][i])\n",
    "        value.append(data[j][i])\n",
    "        sensor.append(j)\n",
    "        time_idx.append(ti)\n",
    "    ti += 1\n",
    "ts_data[\"timestamp\"] = timestamp\n",
    "ts_data[\"sensor\"] = sensor\n",
    "ts_data[\"value\"] = value\n",
    "ts_data[\"time_idx\"] = time_idx\n",
    "id = []\n",
    "for i in range(len(ts_data)):\n",
    "    id.append(i)\n",
    "ts_data[\"id\"] = id\n",
    "# ts_data has 4 columns, timestamp, sensor, value, and time_idx\n",
    "# There is a value for each sensor for each timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up the initial parameters\n",
    "max_prediction_length = int(len(ts_data)*0.4) # 60% training, 40% testing. Feel free to change this ratio if results are not as expected\n",
    "max_encoder_length = 16\n",
    "training_cutoff = ts_data[\"id\"].max() - max_prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = TimeSeriesDataSet(\n",
    "    ts_data[lambda x: x.id <= training_cutoff], # Lambda function to select all data before the cutoff\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"value\",\n",
    "    group_ids=[\"sensor\"], # Required to identify rows uniquely\n",
    "    min_encoder_length=max_encoder_length//2, \n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    add_relative_time_idx=True,\n",
    "    allow_missing_timesteps=False # Set to False as time_idx increases steadily, if this function is edited and time_idx no longer increases steadily must be set to True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = TimeSeriesDataSet(\n",
    "    ts_data[lambda x: x.id > training_cutoff], # Lambda function to select all data before the cutoff\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"value\",\n",
    "    group_ids=[\"sensor\"], # Required to identify rows uniquely\n",
    "    min_encoder_length=max_encoder_length//2, \n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    predict_mode=True,\n",
    "    add_relative_time_idx=True,\n",
    "    allow_missing_timesteps=False # Set to False as time_idx increases steadily, if this function is edited and time_idx no longer increases steadily must be set to True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates dataloaders for the model\n",
    "batch_size = 8  # higher values increase accuracy at cost of CUDA memory\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0) # Num_workers can be increased on multi-core machines\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "#(actuals - baseline_predictions).abs().mean().item() uncomment to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configures the network and trainer for getting hyperparameter values\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=torch.cuda.device_count(), # Set to the amount of GPU's you want to use\n",
    "    gradient_clip_val=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the sample prediction function\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16, \n",
    "    attention_head_size=1, # Can be increased up to 4 for larger datasets\n",
    "    dropout=0.1,  # Between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # Set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    reduce_on_plateau_patience=4, # Reduce learning rate if no improvement in validation loss after x epoch\n",
    ")\n",
    "#print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\") Uncomment to show number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the optimal learning rate\n",
    "torch.cuda.empty_cache()\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "#print(f\"suggested learning rate: {res.suggestion()}\") Uncomment to show learning rate\n",
    "# Plots learning rate to show optimal value\n",
    "#fig = res.plot(show=True, suggest=True) Uncomment to plot learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configures the network and trainer\n",
    "torch.cuda.empty_cache()\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    gpus=1,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # comment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that network or dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the prediction function\n",
    "torch.cuda.empty_cache()\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "#print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\") Uncomment to show number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits the network\n",
    "torch.cuda.empty_cache()\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# Create a study of optimized hyperparameters - Check optuna_test folder for trial logs per epoch\n",
    "# This takes a large amount of time to run so it is only really useful when re-training the model from scratch (can be 1 hour+)\n",
    "torch.cuda.empty_cache()\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200, #This can be increased to increase accuracy at the cost of execution speed\n",
    "    max_epochs=30, # This can be increased to increase accuracy at the cost of execution speed\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save study results so we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best hyperparameters\n",
    "#study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model according to the validation loss (given that we use early stopping, this is not necessarily the last epoch)\n",
    "torch.cuda.empty_cache()\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualtes the mean absolute error on validation set\n",
    "torch.cuda.empty_cache()\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "#(actuals - predictions).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "# This is the only function that needs to be ran if you don't want to update the training, simply enter the data in the best_tft.predict method replacing val_dataloader\n",
    "torch.cuda.empty_cache()\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "\n",
    "for idx in range(len(data.columns)-1):  # plot 10 examples\n",
    "    best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9518128f597d7b00dc14729602cfd87fb7b2cf75925976bcb0d0e328a830a12b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
